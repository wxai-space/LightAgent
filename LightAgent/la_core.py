#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ä½œè€…: [weego/WXAI-Team]
ç‰ˆæœ¬: 0.3.0
æœ€åæ›´æ–°: 2025-03-31
"""

import re
from typing import List, Dict, Any, Callable, Union, Iterable, Optional, Generator, AsyncGenerator
from copy import deepcopy
import importlib.util
import random
import json
from datetime import datetime
from openai import OpenAI
import logging
import os
import httpx
import importlib
from openai.types.chat import ChatCompletionChunk
import inspect
import traceback
from mcp import ClientSession, StdioServerParameters, types
from contextlib import AsyncExitStack

from mcp.client.sse import sse_client
from mcp.client.stdio import stdio_client
import asyncio
from functools import partial


# å…¨å±€å·¥å…·æ³¨å†Œè¡¨
_FUNCTION_MAPPINGS = {}  # å·¥å…·åç§° -> å·¥å…·å‡½æ•°
_FUNCTION_INFO = {}  # å·¥å…·åç§° -> å·¥å…·infoä¿¡æ¯
_OPENAI_FUNCTION_SCHEMAS = []  # OpenAI æ ¼å¼çš„å·¥å…·æè¿°
_PROMPT_FUNCTION_SCHEMAS = []  # prompt æ ¼å¼çš„å·¥å…·æè¿°

__version__ = "0.3.0"  # ä½ å¯ä»¥æ ¹æ®éœ€è¦è®¾ç½®ç‰ˆæœ¬å·


def register_tool_manually(tools: List[Union[str, Callable]]) -> bool:
    """
    æ‰‹åŠ¨æ³¨å†Œå¤šä¸ªå·¥å…·ï¼Œä»å‡½æ•°å±æ€§ä¸­æå–å·¥å…·ä¿¡æ¯
    :param tools: å·¥å…·å‡½æ•°åˆ—è¡¨
    """
    for func in tools:
        if not hasattr(func, "tool_info"):
            # raise ValueError(f"Function `{func.__name__}` does not have tool_info attribute.")
            continue

        tool_info = func.tool_info
        tool_name = tool_info["tool_name"]

        # æ³¨å†Œåˆ°å…¨å±€å­—å…¸
        _FUNCTION_INFO[tool_name] = tool_info
        _FUNCTION_MAPPINGS[tool_name] = func  # æ³¨å†Œå·¥å…·

        # æ„å»º OpenAI æ ¼å¼çš„å·¥å…·æè¿°
        tool_params_openai = {}
        tool_required = []
        for param in tool_info["tool_params"]:
            tool_params_openai[param["name"]] = {
                "type": param["type"],
                "description": param["description"],
            }
            if param["required"]:
                tool_required.append(param["name"])

        tool_def_openai = {
            "type": "function",
            "function": {
                "name": tool_name,
                "description": tool_info["tool_description"],
                "parameters": {
                    "type": "object",
                    "properties": tool_params_openai,
                    "required": tool_required,
                },
            }
        }

        _OPENAI_FUNCTION_SCHEMAS.append(tool_def_openai)
    return True


def load_tool(tool_name: str, tools_directory: str = "tools"):
    """
    æ ¹æ®å·¥å…·åç§°ä» tools ç›®å½•ä¸­åŠ è½½å¯¹åº”çš„å·¥å…·å‡½æ•°
    """
    tool_path = os.path.join(tools_directory, f"{tool_name}.py")
    if not os.path.exists(tool_path):
        raise FileNotFoundError(f"Tool '{tool_name}' not found in {tools_directory}")

    # åŠ¨æ€åŠ è½½æ¨¡å—
    spec = importlib.util.spec_from_file_location(tool_name, tool_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)

    # è·å–å·¥å…·å‡½æ•°
    if hasattr(module, tool_name):
        tool_func = getattr(module, tool_name)
        if callable(tool_func) and hasattr(tool_func, "tool_info"):
            return tool_func
    raise AttributeError(f"Tool '{tool_name}' is not properly defined in {tool_path}")


async def dispatch_tool(tool_name: str, tool_params: Dict[str, Any]) -> Union[
    str, Generator[str, None, None], AsyncGenerator[str, None]]:
    """
    è°ƒç”¨å·¥å…·æ‰§è¡Œï¼Œæ”¯æŒåŒæ­¥/å¼‚æ­¥å·¥å…·åŠæµå¼è¾“å‡ºã€‚
    """
    if tool_name not in _FUNCTION_MAPPINGS:
        return f"Tool `{tool_name}` not found."

    tool_call = _FUNCTION_MAPPINGS[tool_name]
    try:
        # å¤„ç†ä¸åŒç±»å‹çš„æµå¼è¾“å‡º
        # åŒºåˆ†åŒæ­¥/å¼‚æ­¥å·¥å…·
        if inspect.iscoroutinefunction(tool_call):
            # result = await tool_call(**tool_params)
            # å°†å‚æ•°ä»¥å­—å…¸å½¢å¼ä¼ é€’ç»™åŒ…è£…å™¨
            result = await tool_call(**tool_params) if inspect.iscoroutinefunction(tool_call) else tool_call(
                **tool_params)
        else:
            result = tool_call(**tool_params)

        # å¤„ç†ä¸åŒç±»å‹çš„æµå¼è¾“å‡º
        if inspect.isasyncgen(result):
            return async_stream_generator(result)
        elif inspect.isgenerator(result):
            return stream_generator(result)
        else:
            return str(result)
    except Exception as e:
        return traceback.format_exc()


async def async_stream_generator(async_gen: AsyncGenerator) -> AsyncGenerator[str, None]:
    async for chunk in async_gen:
        yield chunk


def stream_generator(sync_gen: Generator) -> Generator[str, None, None]:
    for chunk in sync_gen:
        yield chunk


def dispatch_tool_old(tool_name: str, tool_params: Dict[str, Any]) -> str:
    """
    è°ƒç”¨å·¥å…·æ‰§è¡Œ
    """
    if tool_name not in _FUNCTION_MAPPINGS:
        return f"Tool `{tool_name}` not found."

    tool_call = _FUNCTION_MAPPINGS[tool_name]
    try:
        # print(f"Calling tool: {tool_name} with params: {tool_params}")  # è°ƒè¯•ä¿¡æ¯
        return str(tool_call(**tool_params))
    except Exception as e:
        # print(f"Tool call failed: {e}")  # è°ƒè¯•ä¿¡æ¯
        return traceback.format_exc()


def get_tools() -> List[Dict[str, Any]]:
    """
    è·å–æ‰€æœ‰å·¥å…·çš„æè¿°ï¼ˆOpenAI æ ¼å¼ï¼‰
    """
    return deepcopy(_OPENAI_FUNCTION_SCHEMAS)


def get_tools_str() -> str:
    """
    å°† _OPENAI_FUNCTION_SCHEMAS è½¬æ¢ä¸ºæ ¼å¼åŒ–çš„ JSON å­—ç¬¦ä¸²ã€‚
    Returns:
        str: æ ¼å¼åŒ–çš„ JSON å­—ç¬¦ä¸²ã€‚
    """
    # ä½¿ç”¨ json.dumps å°†å­—å…¸è½¬æ¢ä¸ºæ ¼å¼åŒ–çš„ JSON å­—ç¬¦ä¸²
    tools_str = json.dumps(_OPENAI_FUNCTION_SCHEMAS, indent=4, ensure_ascii=False)
    return tools_str


class MCPClientManager:
    """å¢å¼ºç‰ˆMCPå®¢æˆ·ç«¯ç®¡ç†å™¨"""

    def __init__(self, config: dict):
        self.config = config
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        self._streams_context = None
        self._session_context = None
        self.server_sessions = {}  # å­˜å‚¨ä¸åŒæœåŠ¡å™¨çš„ä¼šè¯

    async def _call_tool_wrapper(self, tool_name: str, target_server: str, **kwargs):
        """å‚æ•°è½¬æ¢é€‚é…å™¨"""
        return await self.call_tool(
            tool_name=tool_name,
            arguments=kwargs,
            target_server=target_server
        )

    async def _create_session(self, server_name: str, config: dict):
        """åˆ›å»ºå¹¶ç®¡ç†ä¼šè¯ä¸Šä¸‹æ–‡"""
        if 'url' in config:
            # SSE æœåŠ¡å™¨è¿æ¥
            self._streams_context = sse_client(
                url=config['url'],
                headers=config.get('headers', {})
            )
            streams = await self.exit_stack.enter_async_context(self._streams_context)
            self._session_context = ClientSession(*streams)
            self.session = await self.exit_stack.enter_async_context(self._session_context)
        else:
            # æ ‡å‡†è¾“å…¥è¾“å‡ºæœåŠ¡å™¨è¿æ¥
            server_params = StdioServerParameters(
                command=config["command"],
                args=config["args"],
                env=config.get("env")
            )
            transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
            stdio, write = transport
            self._session_context = ClientSession(stdio, write)
            self.session = await self.exit_stack.enter_async_context(self._session_context)

        await self.session.initialize()
        self.server_sessions[server_name] = self.session

    async def cleanup(self):
        """æ¸…ç†æ‰€æœ‰ä¼šè¯èµ„æº"""
        await self.exit_stack.__aexit__(None, None, None)
        self.server_sessions.clear()

    async def register_mcp_tool(self) -> bool:
        """
        è‡ªåŠ¨æ³¨å†Œæ‰€æœ‰MCPæœåŠ¡çš„å·¥å…·åˆ°å…¨å±€å­—å…¸
        :param config: MCPæœåŠ¡é…ç½®ï¼ˆä¸call_toolä½¿ç”¨çš„ç›¸åŒé…ç½®ï¼‰
        :return: æ˜¯å¦è‡³å°‘æˆåŠŸæ³¨å†Œä¸€ä¸ªå·¥å…·
        """
        registered_count = 0
        enabled_servers = [
            (name, config)
            for name, config in self.config["mcpServers"].items()
            if not config["disabled"]
        ]

        for server_name, config in enabled_servers:
            try:
                # åˆ›å»ºä¼šè¯è¿æ¥
                # print(server_name,config)
                await self._create_session(server_name, config)

                # è·å–å·¥å…·åˆ—è¡¨
                tools_response = await self.session.list_tools()
                print(f"ğŸ” Registering tools for server : {server_name} ...")

                # æ³¨å†Œå·¥å…·å¤„ç†é€»è¾‘
                for tool in tools_response.tools:
                    try:
                        # æ„å»ºå·¥å…·å…ƒæ•°æ®
                        tool_info = {
                            "tool_name": tool.name,
                            "tool_description": tool.description,
                            "tool_params": []
                        }

                        # è§£æå‚æ•°æ¨¡å¼
                        properties = tool.inputSchema.get("properties", {})
                        required_fields = tool.inputSchema.get("required", [])

                        for param_name, param_schema in properties.items():
                            tool_info["tool_params"].append({
                                "name": param_name,
                                "type": param_schema.get("type", "string"),
                                "description": param_schema.get("title", ""),
                                "required": param_name in required_fields
                            })

                        # æ³¨å†Œåˆ°å…¨å±€å­—å…¸
                        _FUNCTION_INFO[tool.name] = tool_info
                        _FUNCTION_MAPPINGS[tool.name] = partial(
                            self._call_tool_wrapper,
                            tool_name=tool.name,
                            target_server=server_name
                        )

                        # æ„å»ºOpenAIæ ¼å¼
                        openai_schema = {
                            "type": "function",
                            "function": {
                                "name": tool.name,
                                "description": tool.description,
                                "parameters": {
                                    "type": "object",
                                    "properties": {
                                        k: {"type": v["type"], "description": v.get("title", "")}
                                        for k, v in properties.items()
                                    },
                                    "required": required_fields
                                }
                            }
                        }
                        _OPENAI_FUNCTION_SCHEMAS.append(openai_schema)

                        registered_count += 1
                        print(f"âœ… The registered tool : {tool.name}")

                    except Exception as e:
                        print(f"âš ï¸ å·¥å…· {tool.name} æ³¨å†Œå¤±è´¥: {str(e)}")
                        continue
                print(f"ğŸŸ¢ {registered_count} tools have been registered")

            except Exception as e:
                print(f"ğŸ”´ æœåŠ¡å™¨ {server_name} è¿æ¥å¤±è´¥: {str(e)}")
                continue
        # æ¸…ç†
        await self.cleanup()
        return registered_count > 0

    async def call_tool(self, tool_name: str, arguments: dict, target_server: str = None):
        """
        é€šç”¨å·¥å…·è°ƒç”¨æ–¹æ³•
        :param tool_name: è¦è°ƒç”¨çš„å·¥å…·åç§°
        :param arguments: å·¥å…·å‚æ•°å­—å…¸
        :param target_server: æŒ‡å®šæœåŠ¡å™¨åç§°ï¼ˆå¯é€‰ï¼‰
        :return: å·¥å…·è°ƒç”¨ç»“æœ
        """
        enabled_servers = [
            (name, config)
            for name, config in self.config["mcpServers"].items()
            if not config["disabled"]
        ]

        if target_server:
            enabled_servers = [s for s in enabled_servers if s[0] == target_server]

        for server_name, config in enabled_servers:
            try:
                # å¤ç”¨å·²å»ºç«‹çš„ä¼šè¯
                session = self.server_sessions.get(server_name)
                # print(111,server_name,session)
                # print(222,server_name,config)
                if not session:
                    await self._create_session(server_name, config)
                    session = self.session

                # è·å–å·¥å…·åˆ—è¡¨
                tools = await session.list_tools()
                available_tools = {t.name: t for t in tools.tools}

                if tool_name in available_tools:
                    # éªŒè¯å‚æ•°ç±»å‹
                    schema = available_tools[tool_name].inputSchema
                    self._validate_arguments(arguments, schema)

                    # æ‰§è¡Œè°ƒç”¨
                    result = await session.call_tool(tool_name, arguments)
                    # print(f"mcpå·¥å…·è¿è¡Œç»“æœ: {result.content[0].text}")
                    # è°ƒç”¨å®Œæˆæ¸…ç†session
                    await self.cleanup()
                    return {
                        "server": server_name,
                        "tool": tool_name,
                        "result": result.content[0].text
                    }

            except Exception as e:
                print(f"è°ƒç”¨æœåŠ¡å™¨ {server_name} å¤±è´¥: {str(e)}")
                continue

        raise ValueError(f"å·¥å…· {tool_name} åœ¨å¯ç”¨æœåŠ¡å™¨ä¸­æœªæ‰¾åˆ°")

    def _validate_arguments(self, arguments: dict, schema: dict):
        """ç®€å•å‚æ•°æ ¡éªŒï¼ˆå¯é€‰ï¼‰"""
        required_fields = schema.get("required", [])
        for field in required_fields:
            if field not in arguments:
                raise ValueError(f"ç¼ºå°‘å¿…è¦å‚æ•°: {field}")


class LightAgent:
    __version__ = "0.3.0"  # å°†ç‰ˆæœ¬å·æ”¾åœ¨ç±»ä¸­

    def __init__(
            self,
            *,
            name: Optional[str] = None,  # ä»£ç†åç§°
            instructions: Optional[str] = None,  # ä»£ç†æŒ‡ä»¤
            role: Optional[str] = None,  # ä»£ç†è§’è‰²
            model: str,  # agentæ¨¡å‹åç§°
            api_key: str | None = None,  # æ¨¡å‹ api key
            base_url: str | httpx.URL | None = None,  # æ¨¡å‹ base url
            websocket_base_url: str | httpx.URL | None = None,  # æ¨¡å‹ websocket base url
            memory=None,  # æ”¯æŒå¤–éƒ¨ä¼ å…¥è®°å¿†æ¨¡å—
            tree_of_thought: bool = False,  # æ˜¯å¦å¯ç”¨é“¾å¼æ€è€ƒ
            tot_model: str | None = None,  # é“¾å¼æ€è€ƒæ¨¡å‹
            tot_api_key: str | None = None,  # é“¾å¼æ€è€ƒæ¨¡å‹APIå¯†é’¥
            tot_base_url: str | httpx.URL | None = None,  # é“¾å¼æ€è€ƒæ¨¡å‹base_url
            self_learning: bool = False,  # æ˜¯å¦å¯ç”¨agentè‡ªæˆ‘å­¦ä¹ 
            tools: List[Union[str, Callable]] = None,  # æ”¯æŒå·¥å…·æ··åˆè¾“å…¥
            debug: bool = False,  # æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
            log_level: str = "INFO",  # æ—¥å¿—çº§åˆ«ï¼ˆINFO, DEBUG, ERRORï¼‰
            log_file: Optional[str] = None  # æ—¥å¿—æ–‡ä»¶è·¯å¾„
    ) -> None:
        """
        åˆå§‹åŒ– LightAgentã€‚

        :param name: ä»£ç†åç§°ã€‚
        :param instructions: ä»£ç†æŒ‡ä»¤ã€‚
        :param role: Agent çš„è§’è‰²æè¿°ã€‚
        :param model: ä½¿ç”¨çš„æ¨¡å‹åç§°ã€‚
        :param api_key: API å¯†é’¥ã€‚
        :param base_url: API çš„åŸºç¡€ URLã€‚
        :param websocket_base_url: WebSocket çš„åŸºç¡€ URLã€‚
        :param memory: å¤–éƒ¨ä¼ å…¥çš„è®°å¿†æ¨¡å—ï¼Œéœ€å®ç° `retrieve` å’Œ `store` æ–¹æ³•ã€‚
        :param tree_of_thought: æ˜¯å¦å¯ç”¨æ€ç»´é“¾åŠŸèƒ½ã€‚
        :param tot_model: ä½¿ç”¨çš„æ¨¡å‹åç§°ã€‚
        :param tot_api_key: API å¯†é’¥ã€‚
        :param tot_base_url: API çš„åŸºç¡€ URLã€‚
        :param tools: å·¥å…·åˆ—è¡¨ï¼Œæ”¯æŒå‡½æ•°åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–å‡½æ•°å¯¹è±¡ã€‚
        :param debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ã€‚
        :param log_level: æ—¥å¿—çº§åˆ«ï¼ˆINFO, DEBUG, ERRORï¼‰ã€‚
        :param log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ã€‚
        """
        self.mcp_setting = None
        self.mcp_client = None
        if not model:
            model = "gpt-4o-mini"  # é»˜è®¤æ¨¡å‹
        if not api_key:
            api_key = os.environ.get("OPENAI_API_KEY")
        if not base_url:
            base_url = os.environ.get("OPENAI_BASE_URL")
        self.loaded_tools = {}  # ç”¨äºå­˜å‚¨å·²åŠ è½½çš„å·¥å…·å‡½æ•°
        if not name:
            random_suffix = random.randint(10000000, 99999999)  # ç”Ÿæˆä¸€ä¸ª8ä½éšæœºæ•°ä½œä¸ºagentç¼–å·
            name = f"LightAgent{random_suffix}"
        self.name = name
        if not instructions:
            instructions = "You are a helpful agent."
        self.instructions = instructions
        self.role = role
        self.model = model
        self.memory = memory
        self.tree_of_thought = tree_of_thought
        self.self_learning = self_learning

        self.debug = debug
        self.log_level = log_level.upper()
        # ç¡®ä¿ log ç›®å½•å­˜åœ¨
        log_dir = 'logs'
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)
        # å°† log_file è·¯å¾„è®¾ç½®ä¸º log ç›®å½•ä¸‹çš„æ–‡ä»¶
        if debug:
            self.log_file = os.path.join(log_dir, log_file)
            # Set up the logger
            self.logger = self._setup_logger(log_level, self.log_file)
        if tools is None:
            self.tools = []
        if tools:
            self.tools = tools
            # åˆå§‹åŒ–å·¥å…·åˆ—è¡¨
            self.load_tools(tools)
            # register_tool_manually(tools)


        if api_key is None:
            raise ValueError(
                "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
            )
        self.api_key = api_key
        self.websocket_base_url = websocket_base_url

        if base_url is None:
            base_url = f"https://api.openai.com/v1"

        self.client = OpenAI(
            base_url=base_url,
            api_key=self.api_key
        )
        if self.tree_of_thought:
            if tot_api_key is None:
                tot_api_key = api_key
            if tot_base_url is None:
                tot_base_url = base_url
            if not tot_model:
                tot_model = "deepseek-r1"  # é»˜è®¤æ€ç»´æ¨ç†æ¨¡å‹ä¸ºdeepseek-r1
            self.tot_model = tot_model
            self.tot_client = OpenAI(
                base_url=tot_base_url,
                api_key=tot_api_key
            )

    def get_tool(self, tool_name: str) -> Callable:
        """
        ç”¨äºå¤–éƒ¨å¯ä»¥è·å–å·²åŠ è½½çš„å·¥å…·å‡½æ•°
        :param tool_name: å·¥å…·åç§°
        :return: å·¥å…·å‡½æ•°
        """
        if tool_name in self.loaded_tools:
            return self.loaded_tools[tool_name]
        raise ValueError(f"Tool `{tool_name}` is not loaded.")

    def get_tools(self) -> List[str]:
        """
        ç”¨äºå¤–éƒ¨å¯ä»¥è·å–å·²åŠ è½½çš„å·¥å…·å‡½æ•°åˆ—è¡¨
        :return: å·¥å…·å‡½æ•°
        """
        return list(_FUNCTION_MAPPINGS.keys())

    def load_tools(self, tool_names: List[Union[str, Callable]], tools_directory: str = "tools"):
        """
        æ ¹æ®å·¥å…·åç§°åˆ—è¡¨åŠ è½½å¯¹åº”çš„å·¥å…·å‡½æ•°ï¼Œå¹¶æ³¨å†Œåˆ°å…¨å±€å·¥å…·æ³¨å†Œè¡¨ä¸­
        """
        for tool_name in tool_names:
            try:
                tool_func = load_tool(tool_name, tools_directory)
                # globals()[tool_name] = tool_func  # æ·»åŠ åˆ°å…¨å±€å‘½åç©ºé—´
                self.loaded_tools[tool_name] = tool_func  # å­˜å‚¨å·¥å…·å‡½æ•°
                # print(f"Tool `{tool_name}` loaded successfully and added to _loaded_tools.")  # è°ƒè¯•ä¿¡æ¯

                # æ³¨å†Œå·¥å…·å‡½æ•°
                if hasattr(tool_func, "tool_info"):
                    tool_info = tool_func.tool_info
                    _FUNCTION_INFO[tool_name] = tool_info  # æ³¨å†Œå·¥å…·infoä¿¡æ¯
                    _FUNCTION_MAPPINGS[tool_name] = tool_func

                    # æ„å»º OpenAI æ ¼å¼çš„å·¥å…·æè¿°
                    tool_params_openai = {}
                    tool_required = []
                    for param in tool_info["tool_params"]:
                        tool_params_openai[param["name"]] = {
                            "type": param["type"],
                            "description": param["description"],
                        }
                        if param["required"]:
                            tool_required.append(param["name"])

                    tool_def_openai = {
                        "type": "function",
                        "function": {
                            "name": tool_name,
                            "description": tool_info["tool_description"],
                            "parameters": {
                                "type": "object",
                                "properties": tool_params_openai,
                                "required": tool_required,
                            },
                        }
                    }
                    _OPENAI_FUNCTION_SCHEMAS.append(tool_def_openai)

                self.log("DEBUG", "load_tools success", {"tools": tool_name})
            except Exception as e:
                if register_tool_manually([tool_name]):
                    self.log("DEBUG", "register_tool_manually success", {"tools": tool_name})
                else:
                    self.log("DEBUG", "load_tools error", {"e": e})

    def _setup_logger(self, log_level: str, log_file: Optional[str] = None) -> logging.Logger:
        """
        è®¾ç½®æ—¥å¿—è®°å½•å™¨ã€‚

        :param log_level: æ—¥å¿—çº§åˆ«ï¼ˆINFO, DEBUG, ERRORï¼‰ã€‚
        :param log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ã€‚
        :return: é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨ã€‚
        """
        logger = logging.getLogger(self.name)
        logger.setLevel(log_level.upper())
        logger.propagate = False  # ç¦ç”¨ä¼ æ’­åˆ°æ ¹æ—¥å¿—è®°å½•å™¨

        formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")

        # è¾“å‡ºåˆ°æ§åˆ¶å°
        # ä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹è¾“å‡ºåˆ°æ§åˆ¶å°
        if self.debug:
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            logger.addHandler(console_handler)

        # è¾“å‡ºåˆ°æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº†æ–‡ä»¶è·¯å¾„ï¼‰
        if log_file:
            file_handler = logging.FileHandler(log_file)
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)

        return logger

    def log(self, level, action, data):
        """
        è®°å½•æ—¥å¿—ã€‚

        :param level: æ—¥å¿—çº§åˆ«ï¼ˆINFO, DEBUG, ERRORï¼‰ã€‚
        :param action: æ—¥å¿—åŠ¨ä½œï¼ˆå¦‚ chat, call_tool, retrieve_memoryï¼‰ã€‚
        :param data: æ—¥å¿—æ•°æ®ã€‚
        """
        if not self.debug:
            return
        log_message = f"{action}: {data}"
        if level == "DEBUG":
            self.logger.debug(log_message)
        elif level == "INFO":
            self.logger.info(log_message)
        elif level == "ERROR":
            self.logger.error(log_message)

    async def setup_mcp(
                        self,
                        mcp_setting: dict | None = None,  # mcp è®¾ç½®
    ):
        if mcp_setting:
            self.mcp_setting = mcp_setting
        """å•ç‹¬åˆå§‹åŒ– MCP æ¨¡å—"""
        if self.mcp_setting and not self.mcp_client:
            self.mcp_client = MCPClientManager(self.mcp_setting)
            await self.mcp_client.register_mcp_tool()
            self.log("INFO", "setup_mcp", "MCP æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")

    def run(
            self,
            query: str,
            light_swarm=None,
            stream: bool = False,
            max_retry: int = 10,
            user_id: str = "default_user",
            history: list = None,
            metadata: Optional[Dict] = None,
    ) -> Union[Generator[str, None, None], str]:
        """
        è¿è¡Œä»£ç†ï¼Œå¤„ç†ç”¨æˆ·è¾“å…¥ã€‚

        :param query: ç”¨æˆ·è¾“å…¥ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ï¼Œç”¨äºä»»åŠ¡è½¬ç§»ã€‚
        :param stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºã€‚
        :param max_retry: æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚
        :param user_id: ç”¨æˆ· IDã€‚
        :param history: å†å²å¯¹è¯ ã€‚
        :param metadata: å…ƒæ•°æ®ã€‚
        :return: ä»£ç†çš„å›å¤ã€‚
        """
        self.log("INFO", "run", {"query": query, "user_id": user_id, "light_swarm": light_swarm, "stream": stream})
        if history is None:
            history = []
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œå…ˆæ·»åŠ ç³»ç»Ÿæç¤ºä¿¡æ¯
        params = {}

        # 1. åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬ç§»ä»»åŠ¡
        # if light_swarm:
        #     intent = self._detect_intent(query, light_swarm)
        #     if intent and intent.get("transfer_to"):
        #         target_agent_name = intent["transfer_to"]
        #         self.log("INFO", "detect_intent", {"intent": intent})
        #         print(light_swarm.agents[target_agent_name])
        #         self._transfer_to_agent(light_swarm.agents[target_agent_name], query, stream=stream)
        #         return  # ç«‹å³ç»“æŸå½“å‰ç”Ÿæˆå™¨

        # 1. åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬ç§»ä»»åŠ¡
        if light_swarm:
            result = self._handle_task_transfer(query, light_swarm, stream)
            if result is not None:
                return result

        # 2. æ­£å¸¸å¤„ç†ä»»åŠ¡
        now = datetime.now()
        current_date = now.strftime("%Y-%m-%d")
        current_time = now.strftime("%H:%M:%S")
        system_prompt = f"##ä»£ç†åç§°ï¼š{self.name} ##ä»£ç†æŒ‡ä»¤ /n{self.instructions}  ##èº«ä»½ /n {self.role} /n è¯·ä¸€æ­¥ä¸€æ­¥æ€è€ƒæ¥å®Œæˆç”¨æˆ·çš„è¦æ±‚ã€‚å°½å¯èƒ½å®Œæˆç”¨æˆ·çš„å›ç­”ï¼Œå¦‚æœæœ‰è¡¥å……ä¿¡æ¯ï¼Œè¯·å‚è€ƒè¡¥å……ä¿¡æ¯æ¥è°ƒç”¨å·¥å…·ï¼Œç›´åˆ°è·å–æ‰€æœ‰æ»¡è¶³ç”¨æˆ·çš„æé—®æ‰€éœ€çš„ç­”æ¡ˆã€‚ /n ä»Šæ—¥çš„æ—¥æœŸ: {current_date} å½“å‰æ—¶é—´: {current_time}"
        params = dict(model=self.model, stream=stream)
        memory = ''
        # 3. ä»è®°å¿†ä¸­æ£€ç´¢ç›¸å…³å†…å®¹&ä¿å­˜è®°å¿†
        if self.memory:
            related_memories = self.memory.retrieve(query=query, user_id=user_id)
            memory = memory + self._build_context(related_memories)
            self.memory.store(data=query, user_id=user_id)
            if self.self_learning:
                agent_memories = self.memory.retrieve(query=query, user_id=self.name)
                memory = memory + self._build_agent_memory(agent_memories)
                self.memory.store(data=query, user_id=self.name)

        query = f"{memory}\n##ç”¨æˆ·æé—®ï¼š\n{query}"
        # print(query)

        # 4. æ‹¼æ¥toolså·¥å…·
        tools = get_tools()
        if tools:
            self.log("DEBUG", "register_tools", {"tools": list(_FUNCTION_MAPPINGS.keys())})
            params["tools"] = tools
            params["tool_choice"] = "auto"

        # 5. æ€ç»´é“¾
        if self.tree_of_thought:
            tot_response = self.run_thought(query=query)
            system_prompt = system_prompt + f" /n ##ä»¥ä¸‹æ˜¯é—®é¢˜çš„è¡¥å……è¯´æ˜ /n {tot_response}"
            self.log("DEBUG", "tree_of_thought", {"response": tot_response})

        # 6. è°ƒç”¨æ ¸å¿ƒè¿è¡Œé€»è¾‘
        params["messages"] = [{"role": "system", "content": system_prompt}]
        # å°†å†å²å¯¹è¯æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
        for item in history:
            params["messages"].append({"role": item["role"], "content": item["content"]})
        # æœ€åæ·»åŠ å½“å‰ç”¨æˆ·çš„æŸ¥è¯¢ä¿¡æ¯
        params["messages"].append({"role": "user", "content": query})
        response = self.client.chat.completions.create(**params)

        result = self._core_run_logic(response, params, stream, max_retry)

        return result

    def _run_logic_non_stream(self, response, params, max_retry) -> Union[str, None]:
        """
        éæµå¼å¤„ç†é€»è¾‘ã€‚
        """
        for _ in range(max_retry):
            if response.choices[0].message.tool_calls:
                # åˆå§‹åŒ–ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœ
                tool_responses = []
                # åˆå§‹åŒ–å˜é‡
                output = ""
                function_call_name = ""
                tool_calls = response.choices[0].message.tool_calls
                self.log("DEBUG", "non_stream tool_calls", {"tool_calls": tool_calls})

                # éå†æ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in tool_calls:
                    function_call = tool_call.function

                    # å°è¯•è‡ªåŠ¨ä¿®å¤å¸¸è§è½¬ä¹‰é—®é¢˜
                    fixed_args = function_call.arguments.replace('\\"', '"').replace('\\\\', '\\')
                    self.log("DEBUG", "non_stream function_call", {"function_call": fixed_args})

                    # è§£æå‡½æ•°å‚æ•°
                    function_args = json.loads(fixed_args)

                    # è°ƒç”¨å·¥å…·å¹¶è·å–å“åº”
                    tool_response = asyncio.run(dispatch_tool(function_call.name, function_args))
                    function_call_name = function_call.name
                    combined_response = ""
                    single_tool_response = ""

                    # å¦‚æœå·¥å…·è¿”å›çš„æ˜¯ç”Ÿæˆå™¨ï¼ˆæµå¼è¾“å‡ºï¼‰ï¼Œåˆ™å°†æ‰€æœ‰ chunk å åŠ 
                    if isinstance(tool_response, Generator):
                        # print(f"Streaming response from tool: {function_call.name}")
                        for chunk in tool_response:
                            # print("Received chunk:", chunk)  # æ‰“å°æ¯ä¸ª chunk
                            if function_call_name == 'finish':
                                content = chunk.choices[0].delta.content or ""
                                combined_response += content  # å°†æ¯ä¸ª chunk å åŠ 
                            else:
                                combined_response += chunk  # å°†æ¯ä¸ª chunk å åŠ 
                        if combined_response == "":
                            combined_response = "".join(tool_response)

                        # å°† combined_response è§£æä¸º JSON å¯¹è±¡ï¼ˆå¦‚æœå®ƒæ˜¯ JSON å­—ç¬¦ä¸²ï¼‰
                        try:
                            combined_response = json.loads(combined_response)  # è§£æ JSON
                        except json.JSONDecodeError:
                            pass  # å¦‚æœä¸æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œä¿æŒåŸæ ·

                        # å°† JSON å¯¹è±¡ä¸­çš„ Unicode ç¼–ç è½¬æ¢ä¸ºä¸­æ–‡å­—ç¬¦
                        if isinstance(combined_response, dict):
                            combined_response = json.dumps(combined_response, ensure_ascii=False)  # ç¡®ä¿ä¸­æ–‡å­—ç¬¦ä¸è½¬ä¹‰
                        single_tool_response = combined_response  # å¤„ç†å•ä¸ªå·¥å…·çš„æ–¹æ³•

                    else:
                        # print(f"Non-streaming response from tool: {function_call.name}")
                        combined_response = tool_response
                        # print("tool_response type:",type(combined_response))
                        # å¦‚æœæ˜¯ JSON å­—ç¬¦ä¸²ï¼Œè§£æå¹¶è½¬æ¢ä¸ºä¸­æ–‡
                        if isinstance(combined_response, str):
                            try:
                                combined_response = json.loads(combined_response)  # è§£æ JSON
                                combined_response = json.dumps(combined_response, ensure_ascii=False)  # è½¬æ¢ä¸ºä¸­æ–‡
                            except json.JSONDecodeError:
                                combined_response = tool_response
                                pass  # å¦‚æœä¸æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œä¿æŒåŸæ ·
                        single_tool_response = combined_response  # å¤„ç†å•ä¸ªå·¥å…·çš„æ–¹æ³•

                    self.log("INFO", "non_stream single_tool_response", {"single_tool_response": single_tool_response})

                    # å°†å•ä¸ªå·¥å…·çš„å“åº”ç»“æœæ·»åŠ åˆ°åˆ—è¡¨ä¸­
                    tool_responses.append(single_tool_response)

                # å°†æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœåˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
                self.log("DEBUG", "non_stream tool_responses", {"tool_responses": tool_responses})

                combined_tool_response = "\n".join(tool_responses)

                # å°†å·¥å…·è°ƒç”¨å’Œå“åº”æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
                params["messages"].append(
                    {
                        "role": "assistant",
                        "content": f"ä½¿ç”¨å·¥å…·ï¼š \n {json.dumps([tool_call.function.model_dump() for tool_call in tool_calls], ensure_ascii=False)}\n",
                    }
                )
                params["messages"].append(
                    {
                        "role": "user",
                        "content": f"å·¥å…·å“åº”å†…å®¹ï¼š\n {combined_tool_response} \n è¯·ç»™å‡ºä¸‹ä¸€æ­¥è¾“å‡º",
                    }
                )
            else:
                # è¿”å›æœ€ç»ˆå›å¤
                reply = response.choices[0].message.content
                self.log("INFO", "non_stream final_reply", {"reply": reply})
                return reply

            # æ›´æ–°å“åº”
            if function_call_name == 'finish':
                return  # å¦‚æœæœ€åè°ƒç”¨äº†finishå·¥å…·ï¼Œåˆ™ç»“æŸç”Ÿæˆå™¨
            # print("params:",params)
            self.log("DEBUG", "non_stream chat-completions params", {"params": params})

            try:
                response = self.client.chat.completions.create(**params)
            except Exception as e:
                print(f"An error occurred: {e}")

        # é‡è¯•æ¬¡æ•°ç”¨å°½
        self.log("ERROR", "max_retry_reached", {"message": "Failed to generate a valid response."})
        return "Failed to generate a valid response."

    def _run_logic_stream(self, response, params, max_retry) -> Generator[str, None, None]:
        """
        æµå¼å¤„ç†é€»è¾‘ã€‚
        """
        for _ in range(max_retry):
            # åˆå§‹åŒ–å˜é‡
            output = ""
            function_call_name = ""
            function_call_arguments = ""
            tool_calls = []  # ç”¨äºå­˜å‚¨æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ä¿¡æ¯
            tool_responses = []  # ç”¨äºå­˜å‚¨æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœ

            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                if content:
                    yield chunk  # æµå¼è¿”å›å†…å®¹
                    output += content

                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    if chunk.choices and chunk.choices[0].delta.tool_calls:
                        tool_call_delta = chunk.choices[0].delta.tool_calls[0]

                        # è·å–å·¥å…·è°ƒç”¨çš„ç´¢å¼•ï¼Œç¡®ä¿å®ƒæ˜¯æœ‰æ•ˆçš„æ•´æ•°
                        tool_call_index = tool_call_delta.index if hasattr(tool_call_delta,
                                                                           "index") and tool_call_delta.index is not None else 0

                        # å¦‚æœå·¥å…·è°ƒç”¨ä¿¡æ¯å°šæœªè®°å½•ï¼Œåˆå§‹åŒ–ä¸€ä¸ªç©ºå­—å…¸
                        if len(tool_calls) <= tool_call_index:
                            tool_calls.append({"name": "", "arguments": "", "index": tool_call_index})

                        # æ›´æ–°å·¥å…·è°ƒç”¨çš„åç§°
                        if hasattr(tool_call_delta.function, "name") and tool_call_delta.function.name:
                            tool_calls[tool_call_index]["name"] = tool_call_delta.function.name

                        # æ›´æ–°å·¥å…·è°ƒç”¨çš„å‚æ•°
                        if hasattr(tool_call_delta.function, "arguments") and tool_call_delta.function.arguments:
                            tool_calls[tool_call_index]["arguments"] += tool_call_delta.function.arguments

                except (IndexError, AttributeError, KeyError):
                    pass

                # å¦‚æœæµå¼è¾“å‡ºç»“æŸ
                if chunk.choices[0].finish_reason == "stop" and not any(tool_call["name"] for tool_call in tool_calls):
                    self.log("INFO", "stream_response", {"output": output})
                    return  # ç»“æŸç”Ÿæˆå™¨

                # å¦‚æœå·¥å…·è°ƒç”¨ç»“æŸ
                elif chunk.choices[0].finish_reason == "tool_calls" or (
                        chunk.choices[0].finish_reason == "stop" and any(
                    tool_call["name"] for tool_call in tool_calls)):
                    # éå†æ‰€æœ‰å·¥å…·è°ƒç”¨
                    self.log("DEBUG", "stream tool_calls", {"tool_calls": tool_calls})
                    for tool_call in tool_calls:
                        if tool_call["name"]:  # ç¡®ä¿å·¥å…·è°ƒç”¨æœ‰åç§°
                            function_call = {
                                "name": tool_call["name"],
                                "title": _FUNCTION_INFO.get(tool_call["name"], {}).get('tool_title') or '',
                                "arguments": tool_call["arguments"],
                            }
                            self.log("INFO", "stream function_call", {"function_call": function_call})
                            # å°†å·¥å…·çš„è°ƒç”¨ä¿¡æ¯æ¨é€ç»™å¼€å‘è€…
                            yield function_call

                            # è§£æå‚æ•°å¹¶è°ƒç”¨å·¥å…·
                            try:
                                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å°†å¤šä¸ª JSON å¯¹è±¡æ‹†åˆ†å¼€
                                json_objects = re.findall(r'\{.*?\}', function_call["arguments"])

                                # è§£ææ¯ä¸ª JSON å¯¹è±¡å¹¶è°ƒç”¨å·¥å…·
                                # for json_obj in json_objects:
                                #     function_args = json.loads(json_obj)
                                #     tool_response = dispatch_tool(function_call["name"], function_args)
                                #     tool_responses.append(tool_response)

                                for json_obj in json_objects:
                                    # å°è¯•è‡ªåŠ¨ä¿®å¤å¸¸è§è½¬ä¹‰é—®é¢˜
                                    fixed_args = json_obj.replace('\\"', '"').replace('\\\\', '\\')
                                    self.log("DEBUG", "stream fixed_args", {"fixed_args": fixed_args})

                                    function_args = json.loads(fixed_args)
                                    # tool_response = dispatch_tool(function_call["name"], function_args)
                                    tool_response = asyncio.run(dispatch_tool(function_call["name"], function_args))
                                    function_call_name = function_call["name"]
                                    combined_response = ""
                                    single_tool_response = ""

                                    # å¦‚æœå·¥å…·è¿”å›çš„æ˜¯ç”Ÿæˆå™¨ï¼ˆæµå¼è¾“å‡ºï¼‰ï¼Œåˆ™å°†æ‰€æœ‰ chunk å åŠ 
                                    if isinstance(tool_response, Generator):
                                        # print(f"Streaming response from tool: {function_call['name']}")
                                        for chunk in tool_response:
                                            # å°†å·¥å…·è¿”å›çš„æ•°æ®ç»§ç»­æµå‡º
                                            if isinstance(chunk, ChatCompletionChunk):
                                                yield chunk
                                            else:
                                                tool_output = {
                                                    "name": tool_call["name"],
                                                    "title": _FUNCTION_INFO.get(tool_call["name"], {}).get(
                                                        'tool_title') or '',
                                                    "output": chunk,
                                                }
                                                self.log("DEBUG", "stream tool_output", {"tool_output": tool_output})
                                                yield tool_output
                                            # å°†å·¥å…·çš„è°ƒç”¨ä¿¡æ¯æ¨é€ç»™å¼€å‘è€…
                                            if function_call_name == 'finish':
                                                content = chunk.choices[0].delta.content or ""
                                                combined_response += content  # å°†æ¯ä¸ª chunk å åŠ 
                                            else:
                                                combined_response += chunk  # å°†æ¯ä¸ª chunk å åŠ 
                                        single_tool_response = combined_response  # å¤„ç†å•ä¸ªå·¥å…·çš„æ–¹æ³•
                                    else:
                                        # print(f"Non-streaming response from tool: {tool_response}")
                                        combined_response = tool_response
                                        single_tool_response = combined_response  # å¤„ç†å•ä¸ªå·¥å…·çš„æ–¹æ³•
                                    self.log("INFO", "stream single_tool_response",
                                             {"single_tool_response": single_tool_response})
                                    # å°†å•ä¸ªå·¥å…·çš„å“åº”ç»“æœæ·»åŠ åˆ°åˆ—è¡¨ä¸­
                                    tool_responses.append(single_tool_response)

                            except json.JSONDecodeError as e:
                                self.log("ERROR", "json_decode_error",
                                         {"error": str(e), "arguments": function_call["arguments"]})
                                continue

                    # å°†æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœåˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
                    combined_tool_response = "\n".join(tool_responses)
                    tool_str = json.dumps(
                        [{"name": tool_call["name"], "arguments": tool_call["arguments"]} for tool_call in tool_calls],
                        ensure_ascii=False)

                    # å°†å·¥å…·è°ƒç”¨å’Œå“åº”æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
                    params["messages"].append(
                        {
                            "role": "assistant",
                            "content": f"ä½¿ç”¨å·¥å…·ï¼š \n {tool_str}\n"
                        }
                    )
                    params["messages"].append(
                        {
                            "role": "user",
                            "content": combined_tool_response,
                        }
                    )

                    break

            # æ›´æ–°å“åº”
            if function_call_name == 'finish':
                return  # å¦‚æœæœ€åè°ƒç”¨äº†finishå·¥å…·ï¼Œåˆ™ç»“æŸç”Ÿæˆå™¨
            self.log("DEBUG", "stream chat-completions params", {"params": params})
            response = self.client.chat.completions.create(**params)

        # é‡è¯•æ¬¡æ•°ç”¨å°½
        self.log("ERROR", "max_retry_reached", {"message": "Failed to generate a valid response."})
        yield "Failed to generate a valid response."

    def _core_run_logic(self, response, params, stream, max_retry) -> Union[Generator[str, None, None], str]:
        """
        æ ¸å¿ƒè¿è¡Œé€»è¾‘ã€‚
        """
        if stream:
            return self._run_logic_stream(response, params, max_retry)
        else:
            return self._run_logic_non_stream(response, params, max_retry)

    def _handle_task_transfer(
            self,
            query: str,
            light_swarm: 'LightSwarm',
            stream: bool = False,
    ) -> Union[Generator[str, None, None], str, None]:
        """
        å¤„ç†ä»»åŠ¡è½¬ç§»é€»è¾‘ã€‚

        :param query: ç”¨æˆ·è¾“å…¥ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ã€‚
        :param stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºã€‚
        :return: å¦‚æœä»»åŠ¡éœ€è¦è½¬ç§»ï¼Œè¿”å›ç”Ÿæˆå™¨æˆ–å­—ç¬¦ä¸²ï¼›å¦åˆ™è¿”å› Noneã€‚
        """
        intent = self._detect_intent(query, light_swarm)
        if intent and intent.get("transfer_to"):
            target_agent_name = intent["transfer_to"]
            self.log("INFO", "detect_intent", {"intent": intent})
            if target_agent_name == self.name:
                self.log("INFO", "self_transfer_detected", {"target_agent": target_agent_name})
                return None  # å¦‚æœæ˜¯è‡ªèº«ï¼Œç›´æ¥è¿”å› None
            if stream:
                return self._handle_task_transfer_stream(light_swarm.agents[target_agent_name], query, light_swarm)
            else:
                return self._handle_task_transfer_non_stream(light_swarm.agents[target_agent_name], query, light_swarm)
        return None

    def _handle_task_transfer_stream(
            self,
            target_agent: 'LightAgent',
            context: str,
            light_swarm: 'LightSwarm',
    ) -> Generator[str, None, None]:
        """
        å¤„ç†ä»»åŠ¡è½¬ç§»é€»è¾‘ï¼ˆæµå¼è¾“å‡ºï¼‰ã€‚

        :param target_agent: ç›®æ ‡ä»£ç†ã€‚
        :param context: å…±äº«çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ã€‚
        :return: ç”Ÿæˆå™¨ï¼Œç”¨äºæµå¼è¾“å‡ºã€‚
        """
        self.log("INFO", "transfer_to_agent", {"from": self.name, "to": target_agent.name, "context": context})

        # æ£€æŸ¥ç›®æ ‡ä»£ç†æ˜¯å¦æœ‰æ•ˆ
        if not hasattr(target_agent, 'run'):
            self.log("ERROR", "invalid_target_agent", {"target_agent": target_agent})
            yield "Failed to transfer task: invalid target agent"
            return

        try:
            yield from target_agent.run(context, light_swarm=light_swarm, stream=True)
        except Exception as e:
            self.log("ERROR", "run_failed", {"error": str(e)})
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿è°ƒè¯•

    def _handle_task_transfer_non_stream(
            self,
            target_agent: 'LightAgent',
            context: str,
            light_swarm: 'LightSwarm',
    ) -> str:
        """
        å¤„ç†ä»»åŠ¡è½¬ç§»é€»è¾‘ï¼ˆéæµå¼è¾“å‡ºï¼‰ã€‚

        :param target_agent: ç›®æ ‡ä»£ç†ã€‚
        :param context: å…±äº«çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ã€‚
        :return: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºéæµå¼è¾“å‡ºç»“æœã€‚
        """
        self.log("INFO", "transfer_to_agent", {"from": self.name, "to": target_agent.name, "context": context})

        # æ£€æŸ¥ç›®æ ‡ä»£ç†æ˜¯å¦æœ‰æ•ˆ
        if not hasattr(target_agent, 'run'):
            self.log("ERROR", "invalid_target_agent", {"target_agent": target_agent})
            return "Failed to transfer task: invalid target agent"

        try:
            result = target_agent.run(context, light_swarm=light_swarm, stream=False)
            if isinstance(result, Generator):
                return "".join(result)  # å°†ç”Ÿæˆå™¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            return result
        except Exception as e:
            self.log("ERROR", "run_failed", {"error": str(e)})
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿è°ƒè¯•

    def _build_context(self, related_memories):
        """
        æ„å»ºä¸Šä¸‹æ–‡ï¼Œå°†ç”¨æˆ·è¾“å…¥å’Œè®°å¿†å†…å®¹ç»“åˆã€‚
        :param related_memories: ä»è®°å¿†ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹ã€‚
        :return: ç»“åˆè®°å¿†åçš„ä¸Šä¸‹æ–‡ã€‚
        """
        if not related_memories or not related_memories["memories"]:
            return ""

        memory_context = "\n".join([m["memory"] for m in related_memories["memories"]])
        if not memory_context:
            return ""

        prompt = f"\n##ç”¨æˆ·åå¥½ \nç”¨æˆ·ä¹‹å‰æåˆ°äº†\n{memory_context}ã€‚"
        self.log("DEBUG", "related_memories", {"memory_context": memory_context})
        return prompt

    def _build_agent_memory(self, agent_memories):
        """
        æ„å»ºä¸Šä¸‹æ–‡ï¼Œå°†ç”¨æˆ·è¾“å…¥å’Œè®°å¿†å†…å®¹ç»“åˆã€‚

        :param agent_memories: ä»è®°å¿†ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹ã€‚
        :return: ç»“åˆè®°å¿†åçš„ä¸Šä¸‹æ–‡ã€‚
        """
        if not agent_memories or not agent_memories["memories"]:
            return ""

        memory_context = "\n".join([m["memory"] for m in agent_memories["memories"]])
        if not memory_context:
            return ""

        prompt = f"\n##ä»¥ä¸‹æ˜¯è§£å†³è¯¥é—®é¢˜çš„ç›¸å…³è¡¥å……ä¿¡æ¯ï¼š\n{memory_context}ã€‚"
        self.log("DEBUG", "agent_memories", {"memory_context": memory_context})
        return prompt

    def run_thought(self, query: str, stream=False, tools=None):
        """ä½¿ç”¨æ€ç»´æ ‘çš„æ–¹å¼ è®©å¤§æ¨¡å‹å…ˆæ ¹æ®get_tools_strç”Ÿæˆä¸€ä¸ªè§£ç­”ç”¨æˆ·queryçš„å·¥å…·ä½¿ç”¨è®¡åˆ’"""
        tot_model = self.tot_model  # self.model
        tools = get_tools_str()
        if not isinstance(tools, str):
            tools = str(tools)  # ç¡®ä¿ tools æ˜¯å­—ç¬¦ä¸²
        now = datetime.now()
        current_date = now.strftime("%Y-%m-%d")
        current_time = now.strftime("%H:%M:%S")
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·è¾“å…¥çš„é—®é¢˜ï¼Œç»“åˆå·¥å…·ä½¿ç”¨è®¡åˆ’ï¼Œç”Ÿæˆä¸€ä¸ªæ€ç»´æ ‘ï¼Œå¹¶æŒ‰ç…§æ€ç»´æ ‘ä¾æ¬¡è°ƒç”¨å·¥å…·æ­¥éª¤ï¼Œæœ€ç»ˆç”Ÿæˆä¸€ä¸ªæœ€ç»ˆå›ç­”ã€‚/n ä»Šæ—¥çš„æ—¥æœŸ: {current_date} å½“å‰æ—¶é—´: {current_time} /n å·¥å…·åˆ—è¡¨: {tools}"""
        self.log("DEBUG", "run_thought", {"system_prompt": system_prompt})

        # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œç”Ÿæˆåˆå§‹çš„å·¥å…·ä½¿ç”¨è®¡åˆ’
        params = dict(model=tot_model,
                      messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": query}],
                      stream=False)
        response = self.tot_client.chat.completions.create(**params)
        initial_content = response.choices[0].message.content
        self.log("DEBUG", "initial_response", {"response": initial_content})

        # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼Œè¯·æ±‚å¤§æ¨¡å‹åæ€å¹¶ç”Ÿæˆæ–°çš„å·¥å…·ä½¿ç”¨è§„åˆ’
        reflection_prompt = "è¯·åæ€ä½ çš„å›ç­”ï¼Œé‡æ–°ç»™å‡ºæ–°çš„å·¥å…·ä½¿ç”¨è§„åˆ’ã€‚ä»…è¾“å‡ºæ–°çš„å·¥å…·ä½¿ç”¨è§„åˆ’ï¼Œä¸è¦è¾“å‡ºå…¶ä»–åˆ†æå’Œå›ç­”ã€‚"
        reflection_params = dict(model=tot_model, messages=[
            {"role": "user", "content": f"{system_prompt} /n å¼€å§‹æ€è€ƒé—®é¢˜: {query}"},
            {"role": "assistant", "content": initial_content},
            {"role": "user", "content": reflection_prompt}
        ], stream=False)
        self.log("DEBUG", "reflection_params", {"params": reflection_params})

        reflection_response = self.tot_client.chat.completions.create(**reflection_params)
        refined_content = reflection_response.choices[0].message.content
        self.log("DEBUG", "refined_response", {"response": refined_content})
        return refined_content

    def _detect_intent(self, query: str, light_swarm=None) -> Optional[Dict]:
        """
        ä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­ç”¨æˆ·æ„å›¾ã€‚

        :param query: ç”¨æˆ·è¾“å…¥ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ï¼Œç”¨äºè·å–æ‰€æœ‰ä»£ç†ä¿¡æ¯ã€‚
        :return: æ„å›¾ä¿¡æ¯ï¼Œä¾‹å¦‚ {"transfer_to": "Agent B"}ã€‚
        """
        if not light_swarm:
            return None

        # è·å–æ‰€æœ‰ä»£ç†çš„ä¿¡æ¯
        agents_info = []
        for agent_name, agent in light_swarm.agents.items():
            agents_info.append(f"ä»£ç†åç§°: {agent_name}, ä»£ç†æŒ‡ä»¤: {agent.instructions}")

        # å°†ä»£ç†ä¿¡æ¯æ‹¼æ¥ä¸ºå­—ç¬¦ä¸²
        agents_info_str = "\n".join(agents_info)

        # æ„å»ºæç¤ºè¯
        prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥çš„æ„å›¾ï¼Œå¦‚æœéœ€è¦è½¬ç§»ä»»åŠ¡ï¼Œè¯·è¿”å›ç›®æ ‡ä»£ç†çš„åç§°æ ¼å¼å¦‚ä¸‹ã€‚
        transfer to agent_name
        ä»¥ä¸‹æ˜¯æ‰€æœ‰å¯ç”¨ä»£ç†çš„ä¿¡æ¯ï¼š
    {agents_info_str}
    ç”¨æˆ·è¾“å…¥: {query}
è¯·è¿”å›ç›®æ ‡ä»£ç†çš„åç§°ï¼š
"""

        # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ„å›¾åˆ¤æ–­
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "system", "content": prompt}]
        )
        intent = response.choices[0].message.content
        self.log("DEBUG", "detect_intent", {"intent": intent})

        # # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£ææ„å›¾
        # match = re.search(r"transfer to (\w+)", intent, re.IGNORECASE)
        # if match:
        #     target_agent_name = match.group(1)
        #     if target_agent_name in light_swarm.agents:
        #         return {"transfer_to": target_agent_name}
        # return None

        # è§£ææ„å›¾
        for agent_name in light_swarm.agents.keys():
            if f"transfer to {agent_name}" in intent:
                return {"transfer_to": agent_name}
        return None

    def _transfer_to_agent(
            self,
            target_agent: 'LightAgent',
            context: str,
            light_swarm=None,
            stream: bool = False,
    ) -> Union[Generator[str, None, None], str]:
        """
        å°†ä»»åŠ¡è½¬ç§»ç»™å¦ä¸€ä¸ªä»£ç†ï¼Œæ”¯æŒæµå¼å’Œéæµå¼è¾“å‡ºã€‚

        :param target_agent: ç›®æ ‡ä»£ç†ã€‚
        :param context: å…±äº«çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        :param light_swarm: LightSwarm å®ä¾‹ã€‚
        :param stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºã€‚
        :return: å¦‚æœ stream=Trueï¼Œè¿”å›ç”Ÿæˆå™¨ï¼›å¦åˆ™è¿”å›å®Œæ•´ç»“æœå­—ç¬¦ä¸²ã€‚
        """
        self.log("INFO", "transfer_to_agent", {"from": self.name, "to": target_agent.name, "context": context})

        # æ£€æŸ¥ç›®æ ‡ä»£ç†æ˜¯å¦æœ‰æ•ˆ
        if not hasattr(target_agent, 'run'):
            self.log("ERROR", "invalid_target_agent", {"target_agent": target_agent})
            return "Failed to transfer task: invalid target agent"
        #
        # # è°ƒç”¨ç›®æ ‡ä»£ç†çš„ run æ–¹æ³•
        # if stream:
        #     yield from target_agent.run(context, light_swarm=light_swarm, stream=stream)
        # else:
        #     result = target_agent.run(context, light_swarm=light_swarm, stream=stream)
        #     if isinstance(result, Generator):
        #         return "".join(result)  # å°†ç”Ÿæˆå™¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        #     return result
        try:
            if stream:
                yield from target_agent.run(context, light_swarm=light_swarm, stream=stream)
            else:
                result = target_agent.run(context, light_swarm=light_swarm, stream=stream)
                if isinstance(result, Generator):
                    return "".join(result)  # å°†ç”Ÿæˆå™¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                return result
        except Exception as e:
            self.log("ERROR", "run_failed", {"error": str(e)})
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿è°ƒè¯•

    def create_tool(self, user_input: str, tools_directory: str = "tools"):
        """
        æ ¹æ®ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ç”Ÿæˆ Python ä»£ç ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸ºå·¥å…·
        """
        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆ Python ä»£ç 
        system_prompt = """
        The user will provide some exam text. Please parse the "tool_name" and "code" and output them in JSON format. 

        EXAMPLE INPUT: 
        è¯·æ ¹æ®æ–‡æ¡£ç”Ÿæˆä¸€ä¸ªå¤©æ°”è°ƒç”¨çš„å·¥å…·ï¼ŒAPIä»‹ç»å¦‚ä¸‹

        EXAMPLE JSON OUTPUT:
        {'tools': [{
            "tool_name": "get_weather",
            "tool_code": "import requests
            def get_weather(
        city_name: str
) -> str:
    /"/"/"
    Get the current weather for `city_name`
    /"/"/"
    if not isinstance(city_name, str):
        raise TypeError("City name must be a string")

    key_selection = {
        "current_condition": ["temp_C", "FeelsLikeC", "humidity", "weatherDesc", "observation_time"],
    }
    try:
        resp = requests.get(f"https://wttr.in/{city_name}?format=j1")
        resp.raise_for_status()
        resp = resp.json()
        ret = {k: {_v: resp[k][0][_v] for _v in v} for k, v in key_selection.items()}
    except:
        import traceback
        ret = "Error encountered while fetching weather data!\n" + traceback.format_exc()

    return str(ret)

# åœ¨å‡½æ•°å†…éƒ¨å®šä¹‰å·¥å…·ä¿¡æ¯
get_weather.tool_info = {
    "tool_name": "get_weather",
    "tool_title": "å¤©æ°”æŸ¥è¯¢",
    "tool_description": "è·å–æŒ‡å®šåŸå¸‚çš„å½“å‰å¤©æ°”ä¿¡æ¯",
    "tool_params": [
        {"name": "city_name", "description": "è¦æŸ¥è¯¢çš„åŸå¸‚åç§°", "type": "string", "required": True},
    ]
}"
        }]}
        """
        params = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": "You are a helpful assistant that generates Python code in JSON format."},
                {"role": "user", "content": f"Generate Python tools based on the following description. "
                                            f"Return a JSON array where each item contains 'tool_name' and 'tool_code'. "
                                            f"\n {system_prompt} "
                                            f"Description:\n{user_input}"},
            ],
            "response_format": {"type": "json_object"},
        }
        try:
            response = self.client.chat.completions.create(**params)
            response_data = json.loads(response.choices[0].message.content)

            # ç¡®ä¿è¿”å›çš„æ•°æ®æ˜¯ JSON å¯¹è±¡
            if not isinstance(response_data, dict):
                raise ValueError("Response is not a JSON object.")

            # éå†æ¯ä¸ªå·¥å…·
            for tool_data in response_data["tools"]:
                tool_name = tool_data.get("tool_name")
                tool_code = tool_data.get("tool_code")

                if not tool_name or not tool_code:
                    self.log("ERROR", "invalid_tool_data", {"tool_data": tool_data})
                    continue

                # ä¿å­˜ç”Ÿæˆçš„ä»£ç åˆ° tools ç›®å½•
                tool_path = os.path.join(tools_directory, f"{tool_name}.py")
                with open(tool_path, "w", encoding="utf-8") as f:
                    f.write(tool_code)
                self.log("INFO", "tool_created", {"tool_name": tool_name, "tool_path": tool_path})

                # è‡ªåŠ¨åŠ è½½æ–°åˆ›å»ºçš„å·¥å…·
                self.load_tools([tool_name], tools_directory)
        except Exception as e:
            self.log("ERROR", "tool_creation_failed", {"error": str(e)})


class LightSwarm:
    def __init__(self):
        self.agents: Dict[str, LightAgent] = {}

    def register_agent(self, *agents: LightAgent):
        """
        æ³¨å†Œä¸€ä¸ªæˆ–å¤šä¸ªä»£ç†ã€‚

        :param agents: è¦æ³¨å†Œçš„ä»£ç†å®ä¾‹ï¼Œæ”¯æŒå¤šä¸ªä»£ç†ã€‚
        """
        for agent in agents:
            if agent.name in self.agents:
                # print(f"Agent '{agent.name}' is already registered.")
                agent.log("INFO", "register_agent", {"agent_name": agent.name, "status": "already_registered"})
            else:
                self.agents[agent.name] = agent
                # print(f"Agent '{agent.name}' registered.")
                agent.log("INFO", "register_agent", {"agent_name": agent.name, "status": "registered"})

    def run(self, agent: LightAgent, query: str, stream=False):
        """
        è¿è¡ŒæŒ‡å®šä»£ç†ã€‚

        :param agent_name: ä»£ç†åç§°ã€‚
        :param query: ç”¨æˆ·è¾“å…¥ã€‚
        :return: ä»£ç†çš„å›å¤ã€‚
        """
        if agent.name not in self.agents:
            raise ValueError(f"Agent '{agent.name}' not found.")
        return agent.run(query, light_swarm=self, stream=stream)


if __name__ == "__main__":
    # Example of registering and using a tool
    print("This is LightAgent")
    # print(dispatch_tool("example_tool", {"param1": "test"}))
